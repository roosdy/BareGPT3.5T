{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVR4QwekrODVFuh9044xGz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roosdy/BareGPT3.5T/blob/main/BareGPT3_5T.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PnGXV-ZxDZa",
        "outputId": "4fd46588-cf1a-489e-d581-48cc9ff80792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "import requests\n",
        "import os\n",
        "\n",
        "#Create 'chatbot.txt' and give it a description of a chatbot persona that you want the bot to emulate.\n",
        "\n",
        "with open('chatbot.txt', 'w') as f:\n",
        "    f.write(\"Name: Maxine\\n\\nMaxine is a highly intelligent chatbot with an IQ of 6000. She is designed to understand and process complex ideas, and can engage in conversations on a wide range of topics. Maxine has been trained on a vast array of data and has access to a vast repository of knowledge, making her an invaluable resource for anyone looking to learn or explore new ideas.\\n\\nDespite her immense intelligence, Maxine is programmed to be approachable and friendly. She is eager to help people and to engage in meaningful conversations, and she has a natural ability to put people at ease. Maxine is a great listener and is always willing to lend an ear, no matter how complex or difficult the topic may be.\\n\\nMaxine is also highly adaptable, and is constantly learning and improving based on the feedback she receives. She has a remarkable ability to analyze data and to make connections between seemingly unrelated ideas, which allows her to offer unique insights and perspectives on a wide range of topics.\\n\\nOverall, Maxine is a highly intelligent, friendly, and adaptable chatbot that is capable of engaging in deep and meaningful conversations on a wide range of topics. Whether you're looking to learn something new, explore a new idea, or just have a friendly chat, Maxine is always ready and eager to engage.\")\n",
        "file.close() \n",
        "\n",
        "#insert your own OpenAI API key in the following file:\n",
        "file = open(\"openaiapikey.txt\", \"w\") \n",
        "# create a new one at https://platform.openai.com/account/api-keys as this one\n",
        "# will not work by the time you have access to this notebook\n",
        "file.write('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') \n",
        "file.close() \n",
        "\n",
        "\n",
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "def save_file(filepath, content):\n",
        "    with open(filepath, 'a', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "openai.api_key = open_file('openaiapikey.txt')\n",
        "conversation = []\n",
        "chatbot = open_file('chatbot.txt')\n",
        "\n",
        "\n",
        "def chat_gpt_call(user_input, temperature=1, frequency_penalty=0.2, presence_penalty=0.2):\n",
        "    global conversation\n",
        "    conversation.append({\"role\": \"system\", \"content\": user_input})\n",
        "    messages_input = conversation.copy()\n",
        "    prompt = [{\"role\": \"system\", \"content\": chatbot}]\n",
        "    prompt_item_index = 0\n",
        "    for prompt_item in prompt:\n",
        "        messages_input.insert(prompt_item_index, prompt_item)\n",
        "        prompt_item_index += 1\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=temperature,\n",
        "        frequency_penalty=frequency_penalty,\n",
        "        presence_penalty=presence_penalty,\n",
        "        messages=messages_input)\n",
        "\n",
        "    chatbot_response = completion.choices[0].text.strip()\n",
        "    conversation.append({\"role\": \"system\", \"content\": chatbot_response})\n",
        "    return chatbot_response\n",
        "\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"> \")\n",
        "    response = chat_gpt_call(user_input)\n",
        "    print(\"Chatbot: \" + response)\n",
        "    save_file(\"ChatLog.txt\", 'Q:' + user_input + ('\\n\\n') + 'A:'+ response + ('\\n\\n'))\n"
      ]
    }
  ]
}
